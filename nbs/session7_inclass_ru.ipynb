{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 7 - Neural Networks for image data\n",
    "\n",
    "In this notebook, we're going to see how we can train simple neural networks using ```TensorFlow```, a machine learning and deep learning framework developed by Google Research. You can find the documentation [here](https://www.tensorflow.org/).\n",
    "\n",
    "We're still working on greyscale images at this point - next week, we'll start thinking about working with full colour images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic tools\n",
    "import numpy as np\n",
    "\n",
    "# tools from sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tools from tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data, train-test split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to download the ```MNIST``` dataset again, so that we compare this pipeline to the baseline benchmarks we created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = fetch_openml('mnist_784', version=1, return_X_y=True) #in reality X and y\n",
    "\n",
    "# normalise data\n",
    "data = data.astype(\"float\")/255.0 #normalize to same size\n",
    "\n",
    "# split data\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(data,\n",
    "                                                    labels, \n",
    "                                                    test_size=0.2) #we know this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to one-hot encoding\n",
    "lb = LabelBinarizer() # uses one-hot encoding on the labels to make numerical representations of labels\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0]) # see: the 1 represent the label of the image, 0 is every other label but the exact one for this img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neural network architecture using ```tf.keras```\n",
    "\n",
    "We're now going to create our neural network using ```TensorFlow```. In particular, we're going to using the ```keras``` wrapper which makes the syntax a bit simpler to work with.\n",
    "\n",
    "The code below makes a fully-connected, feed-forward neural network with the following features:\n",
    "\n",
    "- Input layer of 784\n",
    "- One hidden layer of 256\n",
    "- Second hidden layer of 128\n",
    "- An output layer of 10 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define architecture 784x256x128x10\n",
    "model = Sequential() ## feed forward neural network\n",
    "model.add(Dense(256,  #hidden layer 1 with 256 nodes\n",
    "                input_shape=(784,), # input layer with 784 nodes\n",
    "                activation=\"relu\")) #activation function \"relu\" to avoid vanishing gradient problem\n",
    "model.add(Dense(128, #hidden layer 2 with 128 nodes\n",
    "                activation=\"relu\")) #activation function \"relu\" to avoid vanishing gradient problem\n",
    "model.add(Dense(10, # output layer 10 nodes\n",
    "                activation=\"softmax\")) #generalized logistic function, same as multiclass argument (i.e., we have more than 2 labels)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show summary of model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise model layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do view this, there are some extra things that you can install - ```TensorFlow``` gives you instructions to do that.\n",
    "\n",
    "**NB:** This might not work on Windows (but I'm not sure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True) #requires some installation of stuff, u dont have to do it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model loss function, optimizer, and preferred metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the big differences with ```TensorFlow``` vs ```scikit-learn``` is that we have much more control over how the optimization algorithm works.\n",
    "\n",
    "We initalize the optimizer and then we have to *compile* the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model using SGD\n",
    "sgd = SGD(0.01) #  In SGD optimizer a few samples is being picked up or we can say a few samples being get selected\n",
    "#in a random manner instead taking up the whole dataset for each iteration. The smaller value means ???\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=sgd, #the optimizer sgd\n",
    "              metrics=[\"accuracy\"]) #optimizing accuracy, it could also have been \"precision\" \"recall\" \"F1\" etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and save history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've done that, it's just a case of fitting the model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=10, \n",
    "                    batch_size=32)# instead of training the weigths on an individual image and updating them, it trains on 32 images\n",
    "#and the update the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise using ```matplotlib```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 10), history.history[\"loss\"], label=\"train_loss\")\n",
    "#plt.plot(np.arange(0, 10), history.history[\"val_loss\"], label=\"val_loss\", linestyle=\":\")\n",
    "plt.plot(np.arange(0, 10), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "#plt.plot(np.arange(0, 10), history.history[\"val_accuracy\"], label=\"val_acc\", linestyle=\":\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do a little bit of extra work to get the classification report to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(X_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0]) #these are one-hot encoding (dummy variable essentially)\n",
    "print(predictions[0]) #probabilities\n",
    "#see these are not same format, thats why we do the following below (searchin for the highest value in both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.argmax(axis=1),  #take where the label is largest (i.e., 1) (it's original label)\n",
    "                            predictions.argmax(axis=1), #take where the prediction is largest (probability) (the predicted label)\n",
    "                            target_names=[str(x) for x in lb.classes_])) #compare the above 2 and make metrics report "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "1. Turn the above into a ```.py``` script which can be run from the command line. Use argparse if you think it's relevant!\n",
    "2. Use this notebook as a template to train a neural network on the ```Cifar-10``` dataset instead of ```MNIST```.\n",
    "3. Turn *that* notebook into a ```.py``` script, too"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
<<<<<<< HEAD
<<<<<<< HEAD
   "pygments_lexer": "ipython3"
=======
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
>>>>>>> 7d2b6593d571f37dcc57da82b96e51d56bb34475
=======
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
>>>>>>> 7d2b6593d571f37dcc57da82b96e51d56bb34475
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
